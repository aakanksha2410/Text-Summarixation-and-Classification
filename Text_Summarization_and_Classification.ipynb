{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summarization and Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyBJS6NyPTcY"
      },
      "source": [
        "# **Text Summarization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqvDvn1oKib9"
      },
      "source": [
        "original_text = 'Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children. They generally ask for the junk food daily because they have been trend so by their parents from the childhood. They never have been discussed by their parents about the harmful effects of junk foods over health. According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways. They are generally fried food found in the market in the packets. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. It makes able a person to gain excessive weight which is called as obesity. Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes. In type-2 diabetes our body become unable to regulate blood sugar level. Risk of getting this disease is increasing as one become more obese or overweight. It increases the risk of kidney failure. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol. High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning. One who like junk food develop more risk to put on extra weight and become fatter and unhealthier. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Reflexes and senses of the people eating this food become dull day by day thus they live more sedentary life. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure. Above all, you can get various nutritional deficiencies when you don’t consume the essential nutrients, vitamins, minerals and more. You become prone to cardiovascular diseases due to the consumption of bad cholesterol and fat plus sodium. In other words, all this interferes with the functioning of your heart. Furthermore, junk food contains a higher level of carbohydrates. It will instantly spike your blood sugar levels. This will result in lethargy, inactiveness, and sleepiness. A person reflex becomes dull overtime and they lead an inactive life. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. Their taste buds must be developed as such that they find healthy food tasty. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help. Children will find one way or the other to have it. Make sure you give them junk food in limited quantities and at healthy periods of time. '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "YLTjYD_FKuY9",
        "outputId": "d8c3f087-5f9e-4519-85b5-b54a2805a5c4"
      },
      "source": [
        "original_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Junk foods taste good that’s why it is mostly liked by everyone of any age group especially kids and school going children. They generally ask for the junk food daily because they have been trend so by their parents from the childhood. They never have been discussed by their parents about the harmful effects of junk foods over health. According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways. They are generally fried food found in the market in the packets. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. It makes able a person to gain excessive weight which is called as obesity. Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes. In type-2 diabetes our body become unable to regulate blood sugar level. Risk of getting this disease is increasing as one become more obese or overweight. It increases the risk of kidney failure. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol. High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning. One who like junk food develop more risk to put on extra weight and become fatter and unhealthier. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Reflexes and senses of the people eating this food become dull day by day thus they live more sedentary life. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is the easiest way to gain unhealthy weight. The amount of fats and sugar in the food makes you gain weight rapidly. However, this is not a healthy weight. It is more of fats and cholesterol which will have a harmful impact on your health. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. The amount of calorie your body requires to stay fit is not fulfilled by this food. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and high blood pressure. This may also result in kidney failure. Above all, you can get various nutritional deficiencies when you don’t consume the essential nutrients, vitamins, minerals and more. You become prone to cardiovascular diseases due to the consumption of bad cholesterol and fat plus sodium. In other words, all this interferes with the functioning of your heart. Furthermore, junk food contains a higher level of carbohydrates. It will instantly spike your blood sugar levels. This will result in lethargy, inactiveness, and sleepiness. A person reflex becomes dull overtime and they lead an inactive life. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. When the time comes, it is too late. Most importantly, the issue is that it does not impact you instantly. It works on your overtime; you will face the consequences sooner or later. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. Their taste buds must be developed as such that they find healthy food tasty. Moreover, try to mix things up. Do not serve the same green vegetable daily in the same style. Incorporate different types of healthy food in their diet following different recipes. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help. Children will find one way or the other to have it. Make sure you give them junk food in limited quantities and at healthy periods of time. '"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVNrBRqEQdZt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKZ2XJKkKw4J"
      },
      "source": [
        "# Importing package and summarizer\n",
        "import gensim\n",
        "from gensim.summarization import summarize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJuuhSMeK2z_",
        "outputId": "b1a2596a-4bd6-44de-cb9e-41ec89d58549"
      },
      "source": [
        "# Passing the text corpus to summarizer\n",
        "short_summary = summarize(original_text)\n",
        "print(short_summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers.\n",
            "Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life.\n",
            "Junk foods tastes good and looks good however do not fulfil the healthy calorie requirement of the body.\n",
            "It is found according to the Centres for Disease Control and Prevention that Kids and children eating junk food are more prone to the type-2 diabetes.\n",
            "Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers.\n",
            "It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol.\n",
            "High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning.\n",
            "One who like junk food develop more risk to put on extra weight and become fatter and unhealthier.\n",
            "Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert.\n",
            "For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lc_V-qzK4tR",
        "outputId": "757fe3ff-d3fc-44e1-9bef-43071264a28a"
      },
      "source": [
        "# Summarization by ratio\n",
        "summary_by_ratio=summarize(original_text,ratio=0.1)\n",
        "print(summary_by_ratio)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers.\n",
            "Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life.\n",
            "Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers.\n",
            "It increases risk of cardiovascular diseases because it is rich in saturated fat, sodium and bad cholesterol.\n",
            "High sodium and bad cholesterol diet increases blood pressure and overloads the heart functioning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA63KCTBK9bk",
        "outputId": "75afbdb9-b214-402f-cb9f-218724690a68"
      },
      "source": [
        "# Summarization by word count\n",
        "summary_by_word_count=summarize(original_text,word_count=30)\n",
        "print(summary_by_word_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaJ44QQJK_uY",
        "outputId": "c4f5e9db-43f4-494c-8c6b-ec25fa3147c3"
      },
      "source": [
        "# Summarization when both ratio & word count is given\n",
        "summary=summarize(original_text, ratio=0.1, word_count=30)\n",
        "print(summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCswEMsCONIY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3WR3272Re2k",
        "outputId": "54b84b75-dbf7-43d1-8683-bb43f8a3d6d8"
      },
      "source": [
        "# importing libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# Input text - to summarize\n",
        "#text = \"\"\" \"\"\"\n",
        "\n",
        "# Tokenizing the text\n",
        "stopWords = set(stopwords.words(\"english\"))\n",
        "words = word_tokenize(original_text)\n",
        "\n",
        "# Creating a frequency table to keep the\n",
        "# score of each word\n",
        "\n",
        "freqTable = dict()\n",
        "for word in words:\n",
        "\tword = word.lower()\n",
        "\tif word in stopWords:\n",
        "\t\tcontinue\n",
        "\tif word in freqTable:\n",
        "\t\tfreqTable[word] += 1\n",
        "\telse:\n",
        "\t\tfreqTable[word] = 1\n",
        "\n",
        "# Creating a dictionary to keep the score\n",
        "# of each sentence\n",
        "sentences = sent_tokenize(original_text)\n",
        "sentenceValue = dict()\n",
        "\n",
        "for sentence in sentences:\n",
        "\tfor word, freq in freqTable.items():\n",
        "\t\tif word in sentence.lower():\n",
        "\t\t\tif sentence in sentenceValue:\n",
        "\t\t\t\tsentenceValue[sentence] += freq\n",
        "\t\t\telse:\n",
        "\t\t\t\tsentenceValue[sentence] = freq\n",
        "\n",
        "\n",
        "\n",
        "sumValues = 0\n",
        "for sentence in sentenceValue:\n",
        "\tsumValues += sentenceValue[sentence]\n",
        "\n",
        "# Average value of a sentence from the original text\n",
        "\n",
        "average = int(sumValues / len(sentenceValue))\n",
        "\n",
        "# Storing sentences into our summary.\n",
        "summary = ''\n",
        "for sentence in sentences:\n",
        "\tif (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
        "\t\tsummary += \" \" + sentence\n",
        "print(summary)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " According to the research by scientists, it has been found that junk foods have negative effects on the health in many ways. They become high in calories, high in cholesterol, low in healthy nutrients, high in sodium mineral, high in sugar, starch, unhealthy fat, lack of protein and lack of dietary fibers. Processed and junk foods are the means of rapid and unhealthy weight gain and negatively impact the whole body throughout the life. Some of the foods like french fries, fried foods, pizza, burgers, candy, soft drinks, baked goods, ice cream, cookies, etc are the example of high-sugar and high-fat containing foods. Eating junk food daily lead us to the nutritional deficiencies in the body because it is lack of essential nutrients, vitamins, iron, minerals and dietary fibers. Junk foods contain high level carbohydrate which spike blood sugar level and make person more lethargic, sleepy and less active and alert. Junk foods are the source of constipation and other disease like diabetes, heart ailments, clogged arteries, heart attack, strokes, etc because of being poor in nutrition. Junk food is also one of the main reasons for the increase in obesity nowadays.This food only looks and tastes good, other than that, it has no positive points. For instance, foods like French fries, burgers, candy, and cookies, all have high amounts of sugar and fats. Furthermore, junk food contains a higher level of carbohydrates. To make things worse, junk food also clogs your arteries and increases the risk of a heart attack. Therefore, it must be avoided at the first instance to save your life from becoming ruined.The main problem with junk food is that people don’t realize its ill effects now. Thus, it is better to stop now.You can avoid junk food by encouraging your children from an early age to eat green vegetables. This will help them to try foods at home rather than being attracted to junk food.In short, do not deprive them completely of it as that will not help.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QEfqqMedvuH"
      },
      "source": [
        "# **Text Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQKpbRSNdzIL",
        "outputId": "e7a40be6-eaeb-4a4c-fb30-106e55909122"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#for text pre-processing\n",
        "import re, string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#for model-building\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "# bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#for word embedding\n",
        "import gensim\n",
        "from gensim.models import Word2Vec #Word2Vec is mostly used for huge datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "wu8qq9-4fIjw",
        "outputId": "edae9655-8f7c-4667-b996-ac68ebeb3735"
      },
      "source": [
        "df_train=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/train_classification.csv')\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7613, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QhECg1cgUIh",
        "outputId": "6ad46e65-ee4f-4f48-bcfe-8ad7ee877e1e"
      },
      "source": [
        "df_train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "keyword       61\n",
              "location    2533\n",
              "text           0\n",
              "target         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ur5YCVvgUFg",
        "outputId": "7264766c-aed2-42c4-b4c7-49476e98881e"
      },
      "source": [
        "#1. WORD-COUNT\n",
        "df_train['word_count'] = df_train['text'].apply(lambda x: len(str(x).split()))\n",
        "print(df_train[df_train['target']==1]['word_count'].mean()) #Disaster tweets\n",
        "print(df_train[df_train['target']==0]['word_count'].mean()) #Non-Disaster tweets\n",
        "#Disaster tweets are more wordy than the non-disaster tweets\n",
        "\n",
        "#2. CHARACTER-COUNT\n",
        "df_train['char_count'] = df_train['text'].apply(lambda x: len(str(x)))\n",
        "print(df_train[df_train['target']==1]['char_count'].mean()) #Disaster tweets\n",
        "print(df_train[df_train['target']==0]['char_count'].mean()) #Non-Disaster tweets\n",
        "#Disaster tweets are longer than the non-disaster tweets\n",
        "\n",
        "#3. UNIQUE WORD-COUNT\n",
        "df_train['unique_word_count'] = df_train['text'].apply(lambda x: len(set(str(x).split())))\n",
        "print(df_train[df_train['target']==1]['unique_word_count'].mean()) #Disaster tweets\n",
        "print(df_train[df_train['target']==0]['unique_word_count'].mean()) #Non-Disaster tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.167532864567411\n",
            "14.704744357438969\n",
            "108.11342097217977\n",
            "95.70681713496084\n",
            "14.664934270865178\n",
            "14.09649930907416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdWx6TwCgUCt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVGcq6s1fUDu"
      },
      "source": [
        "#1. Common text preprocessing\n",
        "\n",
        "#convert to lowercase and remove punctuations and characters and then strip\n",
        "def preprocess(text):\n",
        "    text = text.lower() #lowercase text\n",
        "    text=text.strip()  #get rid of leading/trailing whitespace \n",
        "    text=re.compile('<.*?>').sub('', text) #Remove HTML tags/markups\n",
        "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  #Replace punctuation with space. Careful since punctuation can sometime be useful\n",
        "    text = re.sub('\\s+', ' ', text)  #Remove extra space and tabs\n",
        "    text = re.sub(r'\\[[0-9]*\\]',' ',text) #[0-9] matches any digit (0 to 10000...)\n",
        "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "    text = re.sub(r'\\d',' ',text) #matches any digit from 0 to 100000..., \\D matches non-digits\n",
        "    text = re.sub(r'\\s+',' ',text) #\\s matches any whitespace, \\s+ matches multiple whitespace, \\S matches non-whitespace \n",
        "    \n",
        "    return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVGPTmnJfYLT"
      },
      "source": [
        "#1. STOPWORD REMOVAL\n",
        "def stopword(string):\n",
        "    a= [i for i in string.split() if i not in stopwords.words('english')]\n",
        "    return ' '.join(a)\n",
        "\n",
        "#2. STEMMING\n",
        " \n",
        "# Initialize the stemmer\n",
        "snow = SnowballStemmer('english')\n",
        "def stemming(string):\n",
        "    a=[snow.stem(i) for i in word_tokenize(string) ]\n",
        "    return \" \".join(a)\n",
        "\n",
        "\n",
        "#3. LEMMATIZATION\n",
        "# Initialize the lemmatizer\n",
        "wl = WordNetLemmatizer()\n",
        " \n",
        "# This is a helper function to map NTLK position tags\n",
        "# Full list is available here: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "# Tokenize the sentence\n",
        "def lemmatizer(string):\n",
        "    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags\n",
        "    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token\n",
        "    return \" \".join(a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "F-wz0LCkf9zO",
        "outputId": "cbbaf2c3-9617-409b-885d-b674436e1231"
      },
      "source": [
        "#FINAL PREPROCESSING\n",
        "def finalpreprocess(string):\n",
        "    return lemmatizer(stopword(preprocess(string)))\n",
        "\n",
        "df_train['clean_text'] = df_train['text'].apply(lambda x: finalpreprocess(x))\n",
        "df_train=df_train.drop(columns=['word_count','char_count','unique_word_count'])\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>deed reason earthquake may allah forgive u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>forest fire near la ronge sask canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>resident ask shelter place notify officer evac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>people receive wildfire evacuation order calif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>get sent photo ruby alaska smoke wildfires pou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ... target                                         clean_text\n",
              "0   1     NaN  ...      1         deed reason earthquake may allah forgive u\n",
              "1   4     NaN  ...      1              forest fire near la ronge sask canada\n",
              "2   5     NaN  ...      1  resident ask shelter place notify officer evac...\n",
              "3   6     NaN  ...      1  people receive wildfire evacuation order calif...\n",
              "4   7     NaN  ...      1  get sent photo ruby alaska smoke wildfires pou...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NVSrJC_gCAK",
        "outputId": "842f489f-17c4-4729-8f26-e7b795c61478"
      },
      "source": [
        "# create Word2vec model\n",
        "#here words_f should be a list containing words from each document. say 1st row of the list is words from the 1st document/sentence\n",
        "#length of words_f is number of documents/sentences in your dataset\n",
        "df_train['clean_text_tok']=[nltk.word_tokenize(i) for i in df_train['clean_text']] #convert preprocessed sentence to tokenized sentence\n",
        "model = Word2Vec(df_train['clean_text_tok'],min_count=1)  #min_count=1 means word should be present at least across all documents,\n",
        "#if min_count=2 means if the word is present less than 2 times across all the documents then we shouldn't consider it\n",
        "\n",
        "\n",
        "w2v = dict(zip(model.wv.index2word, model.wv.syn0))  #combination of word and its vector\n",
        "\n",
        "#for converting sentence to vectors/numbers from word vectors result by Word2Vec\n",
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(next(iter(word2vec.values())))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRQ3cLFBg_Cu"
      },
      "source": [
        "#SPLITTING THE TRAINING DATASET INTO TRAINING AND VALIDATION\n",
        " \n",
        "# Input: \"reviewText\", \"rating\" and \"time\"\n",
        "# Target: \"log_votes\"\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_train[\"clean_text\"],\n",
        "                                                  df_train[\"target\"],\n",
        "                                                  test_size=0.2,\n",
        "                                                  shuffle=True)\n",
        "X_train_tok= [nltk.word_tokenize(i) for i in X_train]  #for word2vec\n",
        "X_val_tok= [nltk.word_tokenize(i) for i in X_val]      #for word2vec\n",
        "\n",
        "#TF-IDF\n",
        "# Convert x_train to vector since model can only run on numbers and not words- Fit and transform\n",
        "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
        "X_train_vectors_tfidf = tfidf_vectorizer.fit_transform(X_train) #tfidf runs on non-tokenized sentences unlike word2vec\n",
        "# Only transform x_test (not fit and transform)\n",
        "X_val_vectors_tfidf = tfidf_vectorizer.transform(X_val) #Don't fit() your TfidfVectorizer to your test data: it will \n",
        "#change the word-indexes & weights to match test data. Rather, fit on the training data, then use the same train-data-\n",
        "#fit model on the test data, to reflect the fact you're analyzing the test data only based on what was learned without \n",
        "#it, and the have compatible\n",
        "\n",
        "\n",
        "#Word2vec\n",
        "# Fit and transform\n",
        "modelw = MeanEmbeddingVectorizer(w2v)\n",
        "X_train_vectors_w2v = modelw.transform(X_train_tok)\n",
        "X_val_vectors_w2v = modelw.transform(X_val_tok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwG5x_jrhDhe",
        "outputId": "a019c916-785b-4d5a-e69e-4ee51d894a6a"
      },
      "source": [
        "#FITTING THE CLASSIFICATION MODEL using Logistic Regression(tf-idf)\n",
        "\n",
        "lr_tfidf=LogisticRegression(solver = 'liblinear', C=10, penalty = 'l2')\n",
        "lr_tfidf.fit(X_train_vectors_tfidf, y_train)  #model\n",
        "\n",
        "#Predict y value for test dataset\n",
        "y_predict = lr_tfidf.predict(X_val_vectors_tfidf)\n",
        "y_prob = lr_tfidf.predict_proba(X_val_vectors_tfidf)[:,1]\n",
        " \n",
        "\n",
        "print(classification_report(y_val,y_predict))\n",
        "print('Confusion Matrix:',confusion_matrix(y_val, y_predict))\n",
        " \n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('AUC:', roc_auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.83      0.83       899\n",
            "           1       0.75      0.74      0.74       624\n",
            "\n",
            "    accuracy                           0.79      1523\n",
            "   macro avg       0.79      0.78      0.79      1523\n",
            "weighted avg       0.79      0.79      0.79      1523\n",
            "\n",
            "Confusion Matrix: [[749 150]\n",
            " [165 459]]\n",
            "AUC: 0.8529268631813127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au-sMGmghFrn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}